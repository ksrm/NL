---
title: "Document Term Matrix"
output: html_document
---

```{r}
#exploring text mining/NLP packages
library(wordcloud)
library(tokenizers)
library(tidytext)
library(lsa)
library(corpus)
library(tm)
library(Matrix)
```


```{r}

run<-read.table("C:/Users/12055/Downloads/run example.txt", row.names=c("doc1", "doc2","doc3"),nrows=3)

traces<-t(cbind(doc1,doc2,doc3))
detectTerms<-as.factor(traces)

uniqueterms<-unique(detectTerms)
print(uniqueterms)

class(traces[1,1])
print(traces)
unique(traces)

run<-read.table("C:/Users/12055/Downloads/run example.txt")
class(run)
unique(run)
?unique
run<-as.matrix(run,nrow=3, ncol=7,byrow=TRUE) 
run
unique(run[1:3,])

doc1<-run[1,]
doc2<-run[2,]
doc3<-run[3,]
traces<-cbind(doc1,doc2,doc3)

frequency<-function(x){
  for (i in x)
  { 
  for(j in x)
  {return(as.numeric(x== uniqueterms))
  }
  }}
frequency(run)
    #evaluate for words  

print(x== "I")
(x== (c("I", "run", "a", "lot", "what", "do", "think")))
```


```{r}
#3 LINE EXAMPLE TEXT

run<-readLines("C:/Users/12055/Downloads/run example.txt")
docs<-Corpus(VectorSource(run))
inspect(docs)
dtm<-TermDocumentMatrix(docs)
dtm
m<-as.matrix(dtm)
t(m)

v<-sort(rowSums(m), decreasing=TRUE)
d<-data.frame(word=names(v), freq=v)
t(d)
#wordcloud
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35,         colors=brewer.pal(8, "Dark2"))

#TASA bag of words

#need to reduce vector size
TASA<-readLines("C:/Users/12055/Documents/CUNY - Undergrad/CUNY BA/Summer 2021/Reading/August 18 2021/TASA/TASA/tasaDocsPara.txt")
docs<-Corpus(VectorSource(TASA))
inspect(docs)
dtm<-TermDocumentMatrix(docs)
mat <- sparseMatrix(i=dtm$i, j=dtm$j, x=dtm$v,
   dims=c(dtm$nrow, dtm$ncol))
m<-as.matrix(dtm)
v<-sort(rowSums(mat), decreasing=TRUE)
d<-data.frame(word=names(v), freq=v)
t(d)
set.seed(1234)
#using wordcloud to get a sense of text data
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
          
#m<-as.matrix(dtm)
v<-sort(rowSums(m), decreasing=TRUE)
d<-data.frame(word=names(v), freq=v)
t(d)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

#ALICE

#preprocessing
Alice<-readLines("C:/Users/12055/Documents/CUNY - Undergrad/CUNY BA/Summer 2021/Reading/August 18 2021/Alice.txt")
head(Alice, n=100)
tolower(Alice)
removePunctuation(Alice)
```



```{r}
#TASA SMALL FILE
TASA_short<-readLines("C:/Users/12055/Documents/CUNY - Undergrad/CUNY BA/Summer 2021/Reading/August 18 2021/TASA/TASA/tasaDocsPara - Sample.txt")
tokenize_words(TASA_short)
tokenize_lines(TASA_short)

TASA_short<-readLines("C:/Users/12055/Documents/CUNY - Undergrad/CUNY BA/Summer 2021/Reading/August 18 2021/TASA/TASA/tasaDocsPara - Sample.txt")
docs<-Corpus(VectorSource(TASA_short))
inspect(docs)
dtm<-TermDocumentMatrix(docs)
dtm
m<-as.matrix(dtm)
t(m)


TASA_short<-read.table("C:/Users/12055/Documents/CUNY - Undergrad/CUNY BA/Summer 2021/Reading/August 18 2021/TASA/TASA/tasaDocsPara - Sample.txt", sep="\t", header=FALSE)
detect_terms<-as.factor(TASA_short)
unique(detect_terms)

frequency<-function(x){
  terms<-"I"
  for (i in x)
  { 
  for(j in x)
  {return(sum(as.numeric(x== terms)))
  }
  }}
frequency(traces)
```

